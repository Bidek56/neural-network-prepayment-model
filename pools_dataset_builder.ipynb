{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import time\n",
    "import imp\n",
    "import os\n",
    "import os, os.path\n",
    "import datetime as dt\n",
    "import dateutil.parser as dp\n",
    "import dill\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of data files (3 groups: regular attributes, GEO, and Seller composition)\n",
    "pools_attributes_files = list()\n",
    "for root, dirs, files in os.walk(\"C:/Users/YuriTurygin/Desktop/NN-PPM/data/pools attributes\"):\n",
    "    for name in files:\n",
    "        pools_attributes_files.append(os.path.join(root, name))        \n",
    "        \n",
    "pools_geo_pct_files = list()\n",
    "for root, dirs, files in os.walk(\"C:/Users/YuriTurygin/Desktop/NN-PPM/data/geo pct\"):\n",
    "    for name in files:\n",
    "        pools_geo_pct_files.append(os.path.join(root, name))  \n",
    "        \n",
    "pools_seller_pct_files = list()\n",
    "for root, dirs, files in os.walk(\"C:/Users/YuriTurygin/Desktop/NN-PPM/data/seller pct\"):\n",
    "    for name in files:\n",
    "        pools_seller_pct_files.append(os.path.join(root, name)) \n",
    "        \n",
    "print(\"# of attr files: \",len(pools_attributes_files))\n",
    "print(\"# of geo pct files: \",len(pools_geo_pct_files))\n",
    "print(\"# of seller pct files: \",len(pools_seller_pct_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all files with regular pool attributes\n",
    "attr_df = pd.DataFrame()\n",
    "for file in pools_attributes_files:\n",
    "    one_month_issue_pools = pd.read_csv(file)\n",
    "    if len(attr_df)==0:\n",
    "        attr_df = one_month_issue_pools\n",
    "    else:\n",
    "        # df1.columns.difference(df2.columns)\n",
    "        # df2.columns.difference(df1.columns)\n",
    "        if all(attr_df.columns == one_month_issue_pools.columns):\n",
    "            attr_df = pd.concat([attr_df,one_month_issue_pools])\n",
    "    print('Done loading ' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env_just_attributes.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all files with pools GEO info\n",
    "geo_df = pd.DataFrame()\n",
    "for file in pools_geo_pct_files:\n",
    "    one_month_issue_pools = pd.read_csv(file)\n",
    "    if len(geo_df)==0:\n",
    "        geo_df = one_month_issue_pools\n",
    "    else:\n",
    "        # df1.columns.difference(df2.columns)\n",
    "        # df2.columns.difference(df1.columns)\n",
    "        if all(geo_df.columns == one_month_issue_pools.columns):\n",
    "            geo_df = pd.concat([geo_df,one_month_issue_pools])\n",
    "    print('Done loading ' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env_attr_and_geo.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all files with pools Seller info\n",
    "seller_df = pd.DataFrame()\n",
    "for file in pools_seller_pct_files:\n",
    "    one_month_issue_pools = pd.read_csv(file)\n",
    "    if len(seller_df)==0:\n",
    "        seller_df = one_month_issue_pools\n",
    "    else:\n",
    "        # df1.columns.difference(df2.columns)\n",
    "        # df2.columns.difference(df1.columns)\n",
    "        if all(seller_df.columns == one_month_issue_pools.columns):\n",
    "            seller_df = pd.concat([seller_df,one_month_issue_pools])\n",
    "    print('Done loading ' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seller_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seller_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env_all_3_dfs.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}